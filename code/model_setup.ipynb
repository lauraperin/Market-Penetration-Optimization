{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA, QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from pygam import LogisticGAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID  DemAffl  DemAge DemClusterGroup DemGender    DemReg DemTVReg  \\\n",
      "0  17147654      5.0     NaN             NaN       NaN       NaN      NaN   \n",
      "1   8415498     15.0     NaN             NaN         M       NaN      NaN   \n",
      "2  12107603      NaN     NaN             NaN         M  Midlands     East   \n",
      "3  14400995      8.0    28.0             NaN         F       NaN      NaN   \n",
      "4  28724674     14.0    67.0             NaN       NaN       NaN      NaN   \n",
      "\n",
      "  LoyalClass  LoyalSpend  LoyalTime  TargetBuy  \n",
      "0        Tin        0.01        5.0          0  \n",
      "1       Gold     8000.00        5.0          1  \n",
      "2        Tin        0.01        NaN          1  \n",
      "3        Tin        0.01        NaN          1  \n",
      "4        Tin        0.01        7.0          0  \n"
     ]
    }
   ],
   "source": [
    "file_path = \"./data/Dataset_10Percent.xlsx\"\n",
    "dataset = pd.read_excel(file_path)\n",
    "print(dataset.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22223, 11)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape\n",
    "# we have 22223 rows and 11 colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DemAffl</th>\n",
       "      <th>DemAge</th>\n",
       "      <th>DemClusterGroup</th>\n",
       "      <th>DemGender</th>\n",
       "      <th>DemReg</th>\n",
       "      <th>DemTVReg</th>\n",
       "      <th>LoyalClass</th>\n",
       "      <th>LoyalSpend</th>\n",
       "      <th>LoyalTime</th>\n",
       "      <th>TargetBuy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17147654</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tin</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8415498</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gold</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12107603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Midlands</td>\n",
       "      <td>East</td>\n",
       "      <td>Tin</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400995</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tin</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28724674</td>\n",
       "      <td>14.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tin</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  DemAffl  DemAge DemClusterGroup DemGender    DemReg DemTVReg  \\\n",
       "0  17147654      5.0     NaN             NaN       NaN       NaN      NaN   \n",
       "1   8415498     15.0     NaN             NaN         M       NaN      NaN   \n",
       "2  12107603      NaN     NaN             NaN         M  Midlands     East   \n",
       "3  14400995      8.0    28.0             NaN         F       NaN      NaN   \n",
       "4  28724674     14.0    67.0             NaN       NaN       NaN      NaN   \n",
       "\n",
       "  LoyalClass  LoyalSpend  LoyalTime  TargetBuy  \n",
       "0        Tin        0.01        5.0          0  \n",
       "1       Gold     8000.00        5.0          1  \n",
       "2        Tin        0.01        NaN          1  \n",
       "3        Tin        0.01        NaN          1  \n",
       "4        Tin        0.01        7.0          0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ID: customer ID\n",
    "- DemAffl: affluence grade on a scale from 1 to 30\n",
    "- DemAge: age, in years\n",
    "- DemCLusterGroup: neighborhood grouo\n",
    "- DemGender: M/F/unkoun\n",
    "- DemReg: Geographic region\n",
    "- DemTVReg: tv region\n",
    "- LoyalClass: loyalty status (tin, silver, gold, platinum)\n",
    "- LoyalSpend: total amount spent\n",
    "- LoyalTime: time as a loyalty card member\n",
    "- Target buy: purchased? yes/no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DemAffl</th>\n",
       "      <th>DemAge</th>\n",
       "      <th>DemClusterGroup</th>\n",
       "      <th>DemGender</th>\n",
       "      <th>DemReg</th>\n",
       "      <th>DemTVReg</th>\n",
       "      <th>LoyalClass</th>\n",
       "      <th>LoyalSpend</th>\n",
       "      <th>LoyalTime</th>\n",
       "      <th>TargetBuy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tin</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gold</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Midlands</td>\n",
       "      <td>East</td>\n",
       "      <td>Tin</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tin</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tin</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DemAffl  DemAge DemClusterGroup DemGender    DemReg DemTVReg LoyalClass  \\\n",
       "0      5.0     NaN             NaN       NaN       NaN      NaN        Tin   \n",
       "1     15.0     NaN             NaN         M       NaN      NaN       Gold   \n",
       "2      NaN     NaN             NaN         M  Midlands     East        Tin   \n",
       "3      8.0    28.0             NaN         F       NaN      NaN        Tin   \n",
       "4     14.0    67.0             NaN       NaN       NaN      NaN        Tin   \n",
       "\n",
       "   LoyalSpend  LoyalTime  TargetBuy  \n",
       "0        0.01        5.0          0  \n",
       "1     8000.00        5.0          1  \n",
       "2        0.01        NaN          1  \n",
       "3        0.01        NaN          1  \n",
       "4        0.01        7.0          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop customer ID as it is a leaker variable\n",
    "dataset=dataset.drop(['ID'],axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DemAffl            1085\n",
       "DemAge             1508\n",
       "DemClusterGroup     674\n",
       "DemGender          2512\n",
       "DemReg              465\n",
       "DemTVReg            465\n",
       "LoyalClass            0\n",
       "LoyalSpend            0\n",
       "LoyalTime           281\n",
       "TargetBuy             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at NAs\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to the high number of NAs and the importance of the variables we will fill them with mean/mode*\n",
    "\n",
    "dataset['DemAffl']=dataset['DemAffl'].fillna(dataset['DemAffl'].mode()[0])\n",
    "dataset['DemAge']=dataset['DemAge'].fillna(dataset['DemAge'].mode()[0])\n",
    "dataset['DemClusterGroup']=dataset['DemClusterGroup'].fillna(dataset['DemClusterGroup'].mode()[0])\n",
    "dataset['DemGender']=dataset['DemGender'].fillna(dataset['DemGender'].mode()[0])\n",
    "dataset['DemReg']=dataset['DemReg'].fillna(dataset['DemReg'].mode()[0])\n",
    "dataset['DemTVReg']=dataset['DemTVReg'].fillna(dataset['DemTVReg'].mode()[0])\n",
    "dataset['LoyalTime']=dataset['LoyalTime'].fillna(dataset['LoyalTime'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DemAffl            0\n",
       "DemAge             0\n",
       "DemClusterGroup    0\n",
       "DemGender          0\n",
       "DemReg             0\n",
       "DemTVReg           0\n",
       "LoyalClass         0\n",
       "LoyalSpend         0\n",
       "LoyalTime          0\n",
       "TargetBuy          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that all valued have been converted\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting categorial variables to numeric\n",
    "\n",
    "We convert categorical variables to numerical format for Machine Learning (ML) in Python because most ML algorithms require numerical input to calculate distances, correlations, and other mathematical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'U': 6}\n",
      "{'F': 0, 'M': 1, 'U': 2}\n",
      "{'Midlands': 0, 'North': 1, 'Scottish': 2, 'South East': 3, 'South West': 4}\n",
      "{'Border': 0, 'C Scotland': 1, 'East': 2, 'London': 3, 'Midlands': 4, 'N East': 5, 'N Scot': 6, 'N West': 7, 'S & S East': 8, 'S West': 9, 'Ulster': 10, 'Wales & West': 11, 'Yorkshire': 12}\n",
      "{'Gold': 0, 'Platinum': 1, 'Silver': 2, 'Tin': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "number = LabelEncoder()\n",
    "\n",
    "dataset['DemClusterGroup'] = number.fit_transform(dataset['DemClusterGroup'].astype('str'))\n",
    "integer_mapping = {l: i for i, l in enumerate(number.classes_)}\n",
    "print(integer_mapping)\n",
    "\n",
    "dataset['DemGender'] = number.fit_transform(dataset['DemGender'].astype('str'))\n",
    "integer_mapping = {l: i for i, l in enumerate(number.classes_)}\n",
    "print(integer_mapping)\n",
    "\n",
    "dataset['DemReg'] = number.fit_transform(dataset['DemReg'].astype('str'))\n",
    "integer_mapping = {l: i for i, l in enumerate(number.classes_)}\n",
    "print(integer_mapping)\n",
    "\n",
    "dataset['DemTVReg'] = number.fit_transform(dataset['DemTVReg'].astype('str'))\n",
    "integer_mapping = {l: i for i, l in enumerate(number.classes_)}\n",
    "print(integer_mapping)\n",
    "\n",
    "dataset['LoyalClass'] = number.fit_transform(dataset['LoyalClass'].astype('str'))\n",
    "integer_mapping = {l: i for i, l in enumerate(number.classes_)}\n",
    "print(integer_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DemAffl</th>\n",
       "      <th>DemAge</th>\n",
       "      <th>DemClusterGroup</th>\n",
       "      <th>DemGender</th>\n",
       "      <th>DemReg</th>\n",
       "      <th>DemTVReg</th>\n",
       "      <th>LoyalClass</th>\n",
       "      <th>LoyalSpend</th>\n",
       "      <th>LoyalTime</th>\n",
       "      <th>TargetBuy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.56467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.56467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DemAffl  DemAge  DemClusterGroup  DemGender  DemReg  DemTVReg  LoyalClass  \\\n",
       "0      5.0    51.0                2          0       3         3           3   \n",
       "1     15.0    51.0                2          1       3         3           0   \n",
       "2      8.0    51.0                2          1       0         2           3   \n",
       "3      8.0    28.0                2          0       3         3           3   \n",
       "4     14.0    67.0                2          0       3         3           3   \n",
       "\n",
       "   LoyalSpend  LoyalTime  TargetBuy  \n",
       "0        0.01    5.00000          0  \n",
       "1     8000.00    5.00000          1  \n",
       "2        0.01    6.56467          1  \n",
       "3        0.01    6.56467          1  \n",
       "4        0.01    7.00000          0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check they have been transformed\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for multicollinearity\n",
    "We check for multicollinearity to ensure that independent variables in a model are not highly correlated, as this can distort the model's coefficients and reduce its predictive accuracy.\n",
    "In this case we will use thr VIF coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DemAffl</td>\n",
       "      <td>7.549453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DemAge</td>\n",
       "      <td>11.185710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DemClusterGroup</td>\n",
       "      <td>3.672943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DemGender</td>\n",
       "      <td>1.469044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DemReg</td>\n",
       "      <td>2.478548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DemTVReg</td>\n",
       "      <td>3.754735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LoyalClass</td>\n",
       "      <td>3.866562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LoyalSpend</td>\n",
       "      <td>1.863544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LoyalTime</td>\n",
       "      <td>3.153694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TargetBuy</td>\n",
       "      <td>1.643008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         variables        VIF\n",
       "0          DemAffl   7.549453\n",
       "1           DemAge  11.185710\n",
       "2  DemClusterGroup   3.672943\n",
       "3        DemGender   1.469044\n",
       "4           DemReg   2.478548\n",
       "5         DemTVReg   3.754735\n",
       "6       LoyalClass   3.866562\n",
       "7       LoyalSpend   1.863544\n",
       "8        LoyalTime   3.153694\n",
       "9        TargetBuy   1.643008"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(z):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = z.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(z.values, i) for i in range(z.shape[1])]\n",
    "\n",
    "    return(vif)\n",
    "\n",
    "z = dataset.iloc[:,0:10]\n",
    "calc_vif(z)\n",
    "# all levels are under the desiderable levels of 10 so all is good to proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our varibale of interest: \n",
    "\n",
    "y = dataset.iloc[:, 9].values\n",
    "X = dataset.iloc[:, 0:9].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataset into training and test (in ratio 80:20)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# we fit the model on the train set and calculate performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing the variables \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary to store results\n",
    "results = []\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    total_error = 1 - accuracy\n",
    "    sensitivity = recall_score(y_true, y_pred)\n",
    "    specificity = TN / (TN + FP)\n",
    "    fdr = FP / (FP + TP) if (FP + TP) != 0 else 0\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return accuracy, total_error, FN, FP, sensitivity, specificity, fdr, precision, f1\n",
    "\n",
    "def append_results(model_name, y_true, y_pred):\n",
    "    metrics = compute_metrics(y_true, y_pred)\n",
    "    results.append([model_name] + list(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "We will fit different models to the data and then choose the top performing one to predict the output on the remaining 90% of clients.\n",
    "\n",
    "Various performance indicators will be taken into consideration:\n",
    "- Accuracy\n",
    "- Total error\n",
    "- False positives\n",
    "- False negatives\n",
    "- Specificity\n",
    "- Sensitivity\n",
    "- False discovery rate\n",
    "- Precision\n",
    "- F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "logistic = LogisticRegression(max_iter=200)\n",
    "logistic.fit(X_train_scaled, y_train)\n",
    "y_pred = logistic.predict(X_test_scaled)\n",
    "append_results(\"Logistic Regression\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\laura\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "y_pred = np.round(lasso.predict(X_test_scaled))\n",
    "append_results(\"Lasso\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "y_pred = np.round(ridge.predict(X_test_scaled))\n",
    "append_results(\"Ridge\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "append_results(\"Decision Tree\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "append_results(\"Random Forest\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "svm = SVC(probability=True)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "append_results(\"SVM\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis\n",
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)\n",
    "y_pred = lda.predict(X_test)\n",
    "append_results(\"LDA\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic Discriminant Analysis\n",
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n",
    "y_pred = qda.predict(X_test)\n",
    "append_results(\"QDA\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "append_results(\"KNN\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized Additive Model\n",
    "gam = LogisticGAM()\n",
    "gam.fit(X_train_scaled, y_train)\n",
    "y_pred = gam.predict(X_test_scaled) > 0.5\n",
    "append_results(\"GAM\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\laura\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "nn = MLPClassifier()\n",
    "nn.fit(X_train_scaled, y_train)\n",
    "y_pred = nn.predict(X_test_scaled)\n",
    "append_results(\"Neural Network\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Method  Accuracy  Total Error    FN   FP  Sensitivity  \\\n",
      "0   Logistic Regression  0.804049     0.195951   691  180     0.358998   \n",
      "1                 Lasso  0.757480     0.242520  1078    0     0.000000   \n",
      "2                 Ridge  0.806749     0.193251   755  104     0.299629   \n",
      "3         Decision Tree  0.714286     0.285714   602  668     0.441558   \n",
      "4         Random Forest  0.792576     0.207424   645  277     0.401670   \n",
      "5                   SVM  0.803825     0.196175   752  120     0.302412   \n",
      "6                   LDA  0.805174     0.194826   691  175     0.358998   \n",
      "7                   QDA  0.804049     0.195951   548  323     0.491651   \n",
      "8                   KNN  0.779978     0.220022   678  300     0.371058   \n",
      "9                   GAM  0.815073     0.184927   613  209     0.431354   \n",
      "10       Neural Network  0.802475     0.197525   670  208     0.378479   \n",
      "\n",
      "    Specificity       FDR  Precision  F1 Score  \n",
      "0      0.946540  0.317460   0.682540  0.470517  \n",
      "1      1.000000  0.000000   0.000000  0.000000  \n",
      "2      0.969112  0.243560   0.756440  0.429236  \n",
      "3      0.801604  0.583916   0.416084  0.428443  \n",
      "4      0.917731  0.390141   0.609859  0.484340  \n",
      "5      0.964360  0.269058   0.730942  0.427822  \n",
      "6      0.948025  0.311388   0.688612  0.471951  \n",
      "7      0.904069  0.378664   0.621336  0.548938  \n",
      "8      0.910900  0.428571   0.571429  0.449944  \n",
      "9      0.937927  0.310089   0.689911  0.530822  \n",
      "10     0.938224  0.337662   0.662338  0.481700  \n"
     ]
    }
   ],
   "source": [
    "# Append results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=[\n",
    "    \"Method\", \"Accuracy\", \"Total Error\", \"FN\", \"FP\", \"Sensitivity\", \"Specificity\", \"FDR\", \"Precision\", \"F1 Score\"\n",
    "])\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the model one chooses depends on the metric one chooses, so it is very important to choose the correct metric for the specific problem we are analizing.\n",
    "\n",
    "Some important considerations are:\n",
    "- Minimize false negatives: Sensitivity (Recall) is crucial here because you want to ensure you don’t miss out on potential customers who might be interested in the new product. A high sensitivity means that most of the true positives (customers who would like the product) are correctly identified\n",
    "- Ensure precision: Precision is also important to avoid wasting samples on customers who are unlikely to be interested. High precision means that the customers identified as interested in the product are more likely to be genuinely interested.\n",
    "- Balance Sensitivity and Precision: F1 Score provides a balance between sensitivity and precision. It is useful when you need to balance between not missing out on potential interested customers and not wasting resources on uninterested ones.\n",
    "- Overall Accuracy: Accuracy is important but should be considered along with sensitivity and precision. It tells you the proportion of correctly classified customers, but it might not be as informative if your dataset is imbalanced.\n",
    "-False Discovery Rate (FDR): Lower FDR means fewer of the samples you distribute will be wasted. A model with a lower FDR will help ensure that the samples are targeted more effectively.\n",
    "\n",
    "Given the resulting metrics here are the models we should prioritize:\n",
    "1. GAM: \n",
    "- Sensitivity: 0.431\n",
    "- Precision: 0.690\n",
    "- F1 Score: 0.531\n",
    "- Accuracy: 0.815\n",
    "- FDR: 0.310\n",
    "GAM has the highest F1 score and good sensitivity, making it a strong candidate for balancing recall and precision.\n",
    "\n",
    "2. Neural network:\n",
    "- Sensitivity: 0.378\n",
    "- Precision: 0.662\n",
    "- F1 Score: 0.482\n",
    "- Accuracy: 0.802\n",
    "- FDR: 0.338\n",
    "Neural Network performs well with a high accuracy and reasonable precision, but slightly lower sensitivity compared to GAM.\n",
    "\n",
    "3. Random forest:\n",
    "- Sensitivity: 0.402\n",
    "- Precision: 0.610\n",
    "- F1 Score: 0.484\n",
    "- Accuracy: 0.793\n",
    "- FDR: 0.390\n",
    "Random Forest is also a good option, with decent performance in sensitivity and precision.\n",
    "\n",
    "4. Quadratic Discriminant Analysis:\n",
    "- Sensitivity: 0.492\n",
    "- Precision: 0.621\n",
    "- F1 Score: 0.549\n",
    "- Accuracy: 0.804\n",
    "- FDR: 0.379\n",
    "QDA has the highest sensitivity and F1 score, which could be particularly useful for identifying potential customers who might be interested in the new product.\n",
    "\n",
    "Final considerations:\n",
    "- GAM (Generalized Additive Model) appears to be the best model overall in your case. It offers a good balance between sensitivity, precision, and F1 score, making it effective for identifying customers who are likely to be interested in your new product.\n",
    "- QDA (Quadratic Discriminant Analysis) is also a strong contender with high sensitivity and F1 score, which makes it valuable for identifying potential customers without missing too many.\n",
    "- Neural Network is a robust model but might require more tuning and computational resources compared to GAM or QDA.\n",
    "\n",
    "I will choose GAM as ti is generally preffered over QDA when it comes to interpretability. GAMs in fact offer a more transparent view of how features contribute to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = gam.predict_proba(X_test_scaled)\n",
    "df = pd.DataFrame(X_test_scaled)  \n",
    "df['actual_outcome'] = y_test\n",
    "df['prob_1'] = probabilities\n",
    "df['prob_0'] = 1 - probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.397576  0.339697  0.240428  0.920658  0.980466  0.766951 -1.439121   \n",
      "1  0.397576 -0.207581 -0.400594 -0.662575  0.980466  0.766951 -1.439121   \n",
      "2  2.191889  0.886975 -1.041616 -0.662575  0.241876  0.157286 -1.439121   \n",
      "3 -1.097685  0.496062  0.240428 -0.662575  0.980466 -0.757212  0.269943   \n",
      "4  0.098523 -0.129398  0.240428 -0.662575 -1.235304 -0.452379  0.269943   \n",
      "\n",
      "          7         8  actual_outcome    prob_1    prob_0  \n",
      "0  1.060786 -0.553946               0  0.101506  0.898494  \n",
      "1  0.202419 -0.123501               0  0.267650  0.732350  \n",
      "2  0.209323  0.091721               0  0.562185  0.437815  \n",
      "3  0.073003 -1.199614               0  0.087344  0.912656  \n",
      "4 -0.121120 -0.123501               0  0.214226  0.785774  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"./data/ModelOutput_10Percent.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classifier_LoyalCustomers']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exporting GAM Classifier to later use in prediction\n",
    "import joblib\n",
    "joblib.dump(gam, 'Classifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
